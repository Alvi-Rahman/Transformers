{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\paraphrase\\paraphraseenv\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('F:\\\\Paraphrase\\\\try_new\\\\model\\\\')\n",
    "tokenizer = T5Tokenizer.from_pretrained('F:\\\\Paraphrase\\\\try_new\\\\tokenizer\\\\')\n",
    "# model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"While it’s easy to get starstruck by its Pro sibling, the OnePlus 9 is a capable alternative at a lower cost. You’re looking at quite a gap, especially in the US where (for some unknown reason), the base 8/128 GB version of the 9 Pro is not available. This means you can have the vanilla phone for $730 or the 12/256 GB Pro for $1,070\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Sentence ::\n",
      "While it’s easy to get starstruck by its Pro sibling, the OnePlus 9 is a capable alternative at a lower cost. You’re looking at quite a gap, especially in the US where (for some unknown reason), the base 8/128 GB version of the 9 Pro is not available. This means you can have the vanilla phone for $730 or the 12/256 GB Pro for $1,070\n",
      "\n",
      "\n",
      "Paraphrased Sentence :: \n",
      "['<pad>', 'Though', 'it', '’', 's', 'easy', 'to', 'get', 'stars', 'truck', 'by', 'its', 'Pro', 'si', 'bling', ',', 'the', '', 'OnePlus', '9', 'is', '', 'a', 'capable', 'alternative', 'at', '', 'a', 'lower', 'cost', '.']\n"
     ]
    }
   ],
   "source": [
    "text =  sentence.split('.')\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "    \n",
    "\n",
    "encoding = tokenizer.prepare_seq2seq_batch(text, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    do_sample=True,\n",
    "    min_length= len(text[0].split()) - 2,\n",
    "    max_length= len(text[0].split()) + 10,\n",
    "    top_k=120,\n",
    "    top_p=0.95,\n",
    "    temperature=0.98,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5,\n",
    "    no_repeat_ngram_size = 5\n",
    ")\n",
    "\n",
    "print (\"\\nOriginal Sentence ::\")\n",
    "print (sentence)\n",
    "print (\"\\n\")\n",
    "print (\"Paraphrased Sentence :: \")\n",
    "\n",
    "sent = tokenizer.batch_decode(random.choice(beam_outputs), skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The prolonged closure of schools is causing an education crisis that may cost Bangladesh and other South Asian countries over $1 trillion in lost earnings in the long run, according to a World Bank report.\n",
      "1: Sri Lanka's closure of schools is causing an education crisis that may cost Bangladesh and other South Asian countries over $1 trillion in lost earnings in the long run, according to a World Bank report.\n",
      "2: The prolonged closure of schools is causing an education crisis that may cost Bangladesh and other South Asian countries over $1 trillion in lost earnings in the long run, according to a World Bank report.\n",
      "3: The prolonged closure of schools is causing an education crisis that may cost Bangladesh and other South Asian countries over $1 trillion in lost earnings in the long run, according to a World Bank report.\n",
      "4: The prolonged closure of schools is causing an education crisis that may cost Bangladesh and other South Asian countries over $1 trillion in lost earnings in the long run, according to a World Bank report.\n"
     ]
    }
   ],
   "source": [
    "final_outputs = []\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    final_outputs.append(sent)\n",
    "    \n",
    "for i,output in enumerate(final_outputs):\n",
    "    print(f'{i}: {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== NEW ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text):\n",
    "    encoding = tokenizer.prepare_seq2seq_batch(input_text, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "    translated = model.generate(input_ids=input_ids, \n",
    "                                attention_mask=attention_masks,\n",
    "                                do_sample=True,\n",
    "                                min_length= len(input_text[0].split()) - 2,\n",
    "                                max_length= len(input_text[0].split()) + 10,\n",
    "                                top_k=120,\n",
    "                                top_p=0.95,\n",
    "                                temperature=0.98,\n",
    "                                early_stopping=True,\n",
    "                                num_return_sequences=1,\n",
    "                                no_repeat_ngram_size = 3\n",
    "                               )\n",
    "    \n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"While it’s easy to get starstruck by its Pro sibling, the OnePlus 9 is a capable alternative at a lower cost. You’re looking at quite a gap, especially in the US where (for some unknown reason), the base 8/128 GB version of the 9 Pro is not available. This means you can have the vanilla phone for $730 or the 12/256 GB Pro for $1,070\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While it’s easy to get starstruck by its Pro sibling, the OnePlus 9 is a capable alternative at a lower cost  You’re looking at quite a gap, especially in the US where (for some unknown reason), the base 8/128 GB version of the 9 Pro is not available  This means you can have the vanilla phone for $730 or the 12/256 GB Pro for $1,070\n",
      "\n",
      "Will the OnePlus 9 be a more affordable alternative to its Android rival, the XDA? In the US, the base 8/128 GB version of the 9 Pro is not available. So where is the gap? If I wanted a new phone with 32 GB RAM, I could buy a 256 GB phone for $700 or the vanilla Galaxy\n"
     ]
    }
   ],
   "source": [
    "context = sentence.split('.')\n",
    "target = get_response(context)\n",
    "\n",
    "print(' '.join(context))\n",
    "print()\n",
    "print(' '.join(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,   37,  359, 2005,   19, 1852,    8,  337, 2005,    5,   37,  359])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reason', 'wherefore', 'ground']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.synonym('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adjective': ['recurring in scattered and irregular or unpredictable instances']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.meaning('sporadic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnePlus has no Synonyms in the API\n",
      "launches, has no Synonyms in the API\n",
      "it's has no Synonyms in the API\n",
      "this has no Synonyms in the API\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for i in text.split()[:-1]:\n",
    "    try:\n",
    "        temp = dictionary.synonym(i)[0]\n",
    "        s+=\" \"+str(temp)\n",
    "    except:\n",
    "        s+=\" \"+str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OnePlus has always enjoyed extensive teaser campaigns for its upcoming product launches, but it's definitely outdone itself this time around.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" OnePlus old person ever bask extended advert race unwanted engineering future generic launches, only it's emphatically break content this clip\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package brown to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package conll2000 to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package crubadan to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package floresta to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package kimmo to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package masc_tagged to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package moses_sample to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package nps_chat to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\omw.zip.\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package ptb to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package rte to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to F:\\Paraphrase\\...\n",
      "[nltk_data]    | Downloading package senseval to F:\\Paraphrase\\...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to F:\\Paraphrase\\...\n"
     ]
    }
   ],
   "source": [
    "nltk.download(download_dir='F:\\\\Paraphrase\\\\',info_or_id='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='F:\\Paraphrase\\try_new\\tokenizer\\', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', '<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "T5Tokenizer.from_pretrained('F:\\\\Paraphrase\\\\try_new\\\\tokenizer\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
