{"cells":[{"metadata":{"id":"i40LWTTARLhB","outputId":"eba272ad-5104-4ad5-b61c-344645d071b1","trusted":true},"cell_type":"code","source":"!pip install torch","execution_count":11,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.7.0)\r\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch) (0.18.2)\r\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\r\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch) (0.6)\r\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch) (1.19.5)\r\n","name":"stdout"}]},{"metadata":{"id":"OVgBK1-_RSXT","trusted":true},"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport pandas as pd\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":18,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"}]},{"metadata":{"id":"PMwhgaJbRSZ7","trusted":true},"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"XcSVJOeIYbmy","trusted":true},"cell_type":"code","source":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\n\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"ORrqE9cKYecC","trusted":true},"cell_type":"code","source":"def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    temp = pd.read_csv('../input/ms-data/ms_all.csv')\n    lines = temp[['#1 String','#2 String']].values\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l] for l in lines]\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b,c=readLangs('eng','para',True)","execution_count":57,"outputs":[{"output_type":"stream","text":"Reading lines...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in c:\n    a.addSentence(d[0])\n    b.addSentence(d[1])","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs","execution_count":93,"outputs":[{"output_type":"execute_result","execution_count":93,"data":{"text/plain":"[]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"gLPGI85HYhJJ","trusted":true},"cell_type":"code","source":"MAX_LENGTH = 512\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filterPairs(temp_2[0])","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"[]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"RFpWYPXlYlZJ","outputId":"df771804-37a8-4c2f-8f19-ad36ac3f72a4","trusted":true},"cell_type":"code","source":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n#     pairs = filterPairs(pairs)\n#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('eng', 'para', True)\nprint(random.choice(pairs))","execution_count":95,"outputs":[{"output_type":"stream","text":"Reading lines...\nRead 3900 sentence pairs\nCounting words...\nCounted words:\npara 10827\neng 10870\n['in july pc related products were the strongest sector with microprocessors up . per cent and drams up . per cent over june .', 'pc related products were the strongest sellers with microprocessors up . percent and drams up . percent the sia said .']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"mxJNzMENZgcp","trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":97,"outputs":[]},{"metadata":{"id":"4LI1ytVoZnR5","trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":98,"outputs":[]},{"metadata":{"id":"v9emlS8TZrEw","trusted":true},"cell_type":"code","source":"class AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":99,"outputs":[]},{"metadata":{"id":"k4qXyVSXZv_5","trusted":true},"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","execution_count":100,"outputs":[]},{"metadata":{"id":"gO9ZOymMZzfx","trusted":true},"cell_type":"code","source":"teacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","execution_count":101,"outputs":[]},{"metadata":{"id":"fME0PIriZ6KJ","trusted":true},"cell_type":"code","source":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":102,"outputs":[]},{"metadata":{"id":"PR_dMwSuZ9sJ","trusted":true},"cell_type":"code","source":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":103,"outputs":[]},{"metadata":{"id":"5MogU8rZaAjy","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","execution_count":104,"outputs":[]},{"metadata":{"id":"KcliQ1GVaDC5","trusted":true},"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        decoder_attentions = torch.zeros(max_length, max_length)\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            decoder_attentions[di] = decoder_attention.data\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]","execution_count":105,"outputs":[]},{"metadata":{"id":"fegVSvhWaGT4","trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","execution_count":106,"outputs":[]},{"metadata":{"id":"Lc1gdUCdaIsY","trusted":true},"cell_type":"code","source":"hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n\ntrainIters(encoder1, attn_decoder1, 75000, print_every=5000)","execution_count":109,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"index 10 is out of bounds for dimension 0 with size 10","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-109-7ea4b06f8a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-103-29eaa6fdc28a>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-101-77785d753587>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[1;32m     19\u001b[0m             input_tensor[ei], encoder_hidden)\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 0 with size 10"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"jVw5SzaMaRJJ","trusted":false},"cell_type":"code","source":"evaluateRandomly(encoder1, attn_decoder1)","execution_count":null,"outputs":[]},{"metadata":{"id":"noH3n3J5aSRo","trusted":false},"cell_type":"code","source":"output_words, attentions = evaluate(\n    encoder1, attn_decoder1, \"je suis trop froid .\")\nplt.matshow(attentions.numpy())","execution_count":null,"outputs":[]},{"metadata":{"id":"A5Elg5a6aVZI","trusted":false},"cell_type":"code","source":"def showAttention(input_sentence, output_words, attentions):\n    # Set up figure with colorbar\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(\n        encoder1, attn_decoder1, input_sentence)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions)\n\n\nevaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n\nevaluateAndShowAttention(\"elle est trop petit .\")\n\nevaluateAndShowAttention(\"je ne crains pas de mourir .\")\n\nevaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")","execution_count":null,"outputs":[]},{"metadata":{"id":"vqUhComTaawB","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"bk3us4CjRSfT","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"n8rZJj_URSiQ","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}